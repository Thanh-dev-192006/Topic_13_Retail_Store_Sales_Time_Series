{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8adab899",
   "metadata": {},
   "source": [
    "# Phân Tích Performance Của 54 Cửa Hàng (Store Performance Analysis)\n",
    "\n",
    "**Mục tiêu:** So sánh giữa các store types, clusters, và locations để hiểu factors ảnh hưởng đến sales.\n",
    "\n",
    "**Datasets:**\n",
    "- `train.csv`: Dữ liệu sales (3M+ records)\n",
    "- `stores.csv`: Metadata của stores (city, state, type, cluster)\n",
    "\n",
    "**Nội dung phân tích:**\n",
    "1. Data Preparation & Merge\n",
    "2. Store-Level Metrics (Total, Average, Variance)\n",
    "3. Top/Bottom Stores Analysis\n",
    "4. Store Type Comparison (A, B, C, D, E)\n",
    "5. Cluster Analysis (1-17)\n",
    "6. Geographic Analysis (City & State)\n",
    "7. Temporal Consistency (Store × Time Heatmap)\n",
    "8. Outlier & Zero-Sales Detection\n",
    "9. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1398d182",
   "metadata": {},
   "source": [
    "## 1. Import Libraries & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Style settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 13\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "\n",
    "print(\"Libraries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aa3411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== DATA LOADING ====\n",
    "# Thử nhiều path để tương thích với cả Windows và Linux\n",
    "import os\n",
    "\n",
    "possible_paths = [\n",
    "    # Relative paths from notebook location\n",
    "    ('../../data/raw/train.csv', '../../data/raw/stores.csv'),\n",
    "    ('../../data/processed/train_cleaned.csv', '../../data/raw/stores.csv'),\n",
    "    # Absolute paths (Linux)\n",
    "    ('/home/user/Topic_13_Retail_Store_Sales_Time_Series/data/raw/train.csv',\n",
    "     '/home/user/Topic_13_Retail_Store_Sales_Time_Series/data/raw/stores.csv'),\n",
    "    # Windows paths (for team members)\n",
    "    (r'D:\\Topic_13_Project\\Topic_13_Retail_Store_Sales_Time_Series\\data\\raw\\train.csv',\n",
    "     r'D:\\Topic_13_Project\\Topic_13_Retail_Store_Sales_Time_Series\\data\\raw\\stores.csv'),\n",
    "    (r'D:\\Topic_13_Project\\Topic_13_Retail_Store_Sales_Time_Series\\data\\processed\\train_cleaned.csv',\n",
    "     r'D:\\Topic_13_Project\\Topic_13_Retail_Store_Sales_Time_Series\\data\\raw\\stores.csv'),\n",
    "]\n",
    "\n",
    "train = None\n",
    "stores = None\n",
    "\n",
    "for train_path, store_path in possible_paths:\n",
    "    try:\n",
    "        train = pd.read_csv(train_path, parse_dates=['date'])\n",
    "        stores = pd.read_csv(store_path)\n",
    "        print(f\"Loaded from:\\n  train: {train_path}\\n  stores: {store_path}\")\n",
    "        break\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "if train is None or stores is None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"DATA NOT FOUND! Please download from Kaggle:\")\n",
    "    print(\"  kaggle competitions download -c store-sales-time-series-forecasting\")\n",
    "    print(\"  Unzip and place train.csv, stores.csv in data/raw/\")\n",
    "    print(\"=\"*60)\n",
    "    raise FileNotFoundError(\"Cannot find train.csv and/or stores.csv\")\n",
    "\n",
    "print(f\"\\ntrain shape: {train.shape}\")\n",
    "print(f\"stores shape: {stores.shape}\")\n",
    "print(f\"Date range: {train['date'].min()} to {train['date'].max()}\")\n",
    "print(f\"Unique stores: {train['store_nbr'].nunique()}\")\n",
    "print(f\"Unique families: {train['family'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766bbe8",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3465a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== DATA QUALITY CHECK ====\n",
    "print(\"=== TRAIN DATA ===\")\n",
    "print(train.dtypes)\n",
    "print(f\"\\nMissing values:\\n{train.isnull().sum()}\")\n",
    "print(f\"\\nZero sales records: {(train['sales'] == 0).sum():,} ({(train['sales'] == 0).mean()*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n=== STORES DATA ===\")\n",
    "print(stores.dtypes)\n",
    "print(f\"\\nMissing values:\\n{stores.isnull().sum()}\")\n",
    "print(f\"\\nStore types: {sorted(stores['type'].unique())}\")\n",
    "print(f\"Clusters: {sorted(stores['cluster'].unique())}\")\n",
    "print(f\"Cities: {stores['city'].nunique()} unique\")\n",
    "print(f\"States: {stores['state'].nunique()} unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb1c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== MERGE TRAIN + STORES ====\n",
    "df = train.merge(stores, on='store_nbr', how='left')\n",
    "print(f\"Merged shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09905bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== AGGREGATE SALES BY STORE ====\n",
    "store_metrics = df.groupby('store_nbr').agg(\n",
    "    total_sales=('sales', 'sum'),\n",
    "    avg_daily_sales=('sales', 'mean'),\n",
    "    median_daily_sales=('sales', 'median'),\n",
    "    std_daily_sales=('sales', 'std'),\n",
    "    max_daily_sales=('sales', 'max'),\n",
    "    zero_sales_count=('sales', lambda x: (x == 0).sum()),\n",
    "    total_records=('sales', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Calculate derived metrics\n",
    "store_metrics['cv'] = store_metrics['std_daily_sales'] / store_metrics['avg_daily_sales']  # Coefficient of Variation\n",
    "store_metrics['zero_sales_pct'] = store_metrics['zero_sales_count'] / store_metrics['total_records'] * 100\n",
    "\n",
    "# Merge with store metadata\n",
    "store_metrics = store_metrics.merge(stores, on='store_nbr', how='left')\n",
    "\n",
    "# Rank stores\n",
    "store_metrics['rank_total'] = store_metrics['total_sales'].rank(ascending=False).astype(int)\n",
    "store_metrics = store_metrics.sort_values('total_sales', ascending=False)\n",
    "\n",
    "print(f\"Store metrics calculated for {len(store_metrics)} stores\")\n",
    "print(f\"\\nTop 5 stores by total sales:\")\n",
    "print(store_metrics[['store_nbr', 'city', 'state', 'type', 'cluster', 'total_sales', 'avg_daily_sales', 'cv', 'zero_sales_pct']].head())\n",
    "print(f\"\\nBottom 5 stores by total sales:\")\n",
    "print(store_metrics[['store_nbr', 'city', 'state', 'type', 'cluster', 'total_sales', 'avg_daily_sales', 'cv', 'zero_sales_pct']].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== SUMMARY STATISTICS ====\n",
    "print(\"=\"*70)\n",
    "print(\"STORE PERFORMANCE OVERVIEW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nTotal stores: {len(store_metrics)}\")\n",
    "print(f\"Total sales (all stores): ${store_metrics['total_sales'].sum():,.0f}\")\n",
    "print(f\"Average total sales per store: ${store_metrics['total_sales'].mean():,.0f}\")\n",
    "print(f\"Median total sales per store: ${store_metrics['total_sales'].median():,.0f}\")\n",
    "\n",
    "# Concentration\n",
    "top5_share = store_metrics.head(5)['total_sales'].sum() / store_metrics['total_sales'].sum() * 100\n",
    "top10_share = store_metrics.head(10)['total_sales'].sum() / store_metrics['total_sales'].sum() * 100\n",
    "bottom10_share = store_metrics.tail(10)['total_sales'].sum() / store_metrics['total_sales'].sum() * 100\n",
    "\n",
    "print(f\"\\nConcentration:\")\n",
    "print(f\"  Top 5 stores: {top5_share:.1f}% of total sales\")\n",
    "print(f\"  Top 10 stores: {top10_share:.1f}% of total sales\")\n",
    "print(f\"  Bottom 10 stores: {bottom10_share:.1f}% of total sales\")\n",
    "print(f\"  Max/Min ratio: {store_metrics['total_sales'].max() / store_metrics['total_sales'].min():.1f}x\")\n",
    "\n",
    "print(f\"\\nZero Sales Analysis:\")\n",
    "print(f\"  Average zero-sales %: {store_metrics['zero_sales_pct'].mean():.1f}%\")\n",
    "print(f\"  Max zero-sales %: {store_metrics['zero_sales_pct'].max():.1f}% (Store {store_metrics.loc[store_metrics['zero_sales_pct'].idxmax(), 'store_nbr']})\")\n",
    "print(f\"  Min zero-sales %: {store_metrics['zero_sales_pct'].min():.1f}% (Store {store_metrics.loc[store_metrics['zero_sales_pct'].idxmin(), 'store_nbr']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc0263a",
   "metadata": {},
   "source": [
    "## 3. Top 10 & Bottom 10 Stores by Total Sales\n",
    "\n",
    "Nhận diện stores có performance cao nhất và thấp nhất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fe8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== BAR CHART: TOP 10 & BOTTOM 10 STORES ====\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Top 10\n",
    "top10 = store_metrics.head(10).sort_values('total_sales', ascending=True)\n",
    "colors_top = [plt.cm.Greens(0.3 + 0.07 * i) for i in range(10)]\n",
    "bars1 = axes[0].barh(\n",
    "    [f\"Store {int(s)} ({c})\" for s, c in zip(top10['store_nbr'], top10['city'])],\n",
    "    top10['total_sales'] / 1e6,\n",
    "    color=colors_top\n",
    ")\n",
    "axes[0].set_xlabel('Total Sales (Million $)')\n",
    "axes[0].set_title('Top 10 Stores by Total Sales', fontweight='bold')\n",
    "for bar, val in zip(bars1, top10['total_sales'] / 1e6):\n",
    "    axes[0].text(bar.get_width() + 0.3, bar.get_y() + bar.get_height()/2,\n",
    "                 f'${val:.1f}M', va='center', fontsize=9)\n",
    "\n",
    "# Bottom 10\n",
    "bottom10 = store_metrics.tail(10).sort_values('total_sales', ascending=True)\n",
    "colors_bot = [plt.cm.Reds(0.3 + 0.07 * i) for i in range(10)]\n",
    "bars2 = axes[1].barh(\n",
    "    [f\"Store {int(s)} ({c})\" for s, c in zip(bottom10['store_nbr'], bottom10['city'])],\n",
    "    bottom10['total_sales'] / 1e6,\n",
    "    color=colors_bot\n",
    ")\n",
    "axes[1].set_xlabel('Total Sales (Million $)')\n",
    "axes[1].set_title('Bottom 10 Stores by Total Sales', fontweight='bold')\n",
    "for bar, val in zip(bars2, bottom10['total_sales'] / 1e6):\n",
    "    axes[1].text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2,\n",
    "                 f'${val:.1f}M', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/top_bottom_stores.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print comparison\n",
    "print(\"\\n=== KEY INSIGHT ===\")\n",
    "best = store_metrics.iloc[0]\n",
    "worst = store_metrics.iloc[-1]\n",
    "print(f\"Best: Store {int(best['store_nbr'])} ({best['city']}, {best['state']}) - Type {best['type']}, Cluster {int(best['cluster'])}\")\n",
    "print(f\"Worst: Store {int(worst['store_nbr'])} ({worst['city']}, {worst['state']}) - Type {worst['type']}, Cluster {int(worst['cluster'])}\")\n",
    "print(f\"Difference: {best['total_sales']/worst['total_sales']:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78612b24",
   "metadata": {},
   "source": [
    "## 4. Sales Distribution by Store Type (A, B, C, D, E)\n",
    "\n",
    "Phân tích xem store type nào có sales cao nhất và có significant difference giữa các types không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STORE TYPE ANALYSIS ====\n",
    "# Count stores per type\n",
    "type_counts = stores['type'].value_counts().sort_index()\n",
    "print(\"Store count by type:\")\n",
    "print(type_counts)\n",
    "\n",
    "# Type-level metrics\n",
    "type_metrics = store_metrics.groupby('type').agg(\n",
    "    num_stores=('store_nbr', 'count'),\n",
    "    total_sales=('total_sales', 'sum'),\n",
    "    avg_total_sales=('total_sales', 'mean'),\n",
    "    median_total_sales=('total_sales', 'median'),\n",
    "    avg_daily=('avg_daily_sales', 'mean'),\n",
    "    avg_cv=('cv', 'mean'),\n",
    "    avg_zero_pct=('zero_sales_pct', 'mean')\n",
    ").round(2)\n",
    "\n",
    "print(\"\\nType-level metrics:\")\n",
    "print(type_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c88d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== BOX PLOTS: SALES BY STORE TYPE ====\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# (A) Box plot: Total sales by type\n",
    "type_order = store_metrics.groupby('type')['total_sales'].median().sort_values(ascending=False).index\n",
    "sns.boxplot(data=store_metrics, x='type', y='total_sales', order=type_order, ax=axes[0], palette='Set2')\n",
    "axes[0].set_title('Total Sales Distribution by Store Type', fontweight='bold')\n",
    "axes[0].set_ylabel('Total Sales ($)')\n",
    "axes[0].set_xlabel('Store Type')\n",
    "axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.0f}M'))\n",
    "\n",
    "# (B) Box plot: Average daily sales by type\n",
    "sns.boxplot(data=store_metrics, x='type', y='avg_daily_sales', order=type_order, ax=axes[1], palette='Set2')\n",
    "axes[1].set_title('Average Daily Sales by Store Type', fontweight='bold')\n",
    "axes[1].set_ylabel('Avg Daily Sales ($)')\n",
    "axes[1].set_xlabel('Store Type')\n",
    "\n",
    "# (C) Box plot: CV (stability) by type\n",
    "sns.boxplot(data=store_metrics, x='type', y='cv', order=type_order, ax=axes[2], palette='Set2')\n",
    "axes[2].set_title('Sales Volatility (CV) by Store Type', fontweight='bold')\n",
    "axes[2].set_ylabel('Coefficient of Variation')\n",
    "axes[2].set_xlabel('Store Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/store_type_boxplots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f831807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STATISTICAL TEST: Kruskal-Wallis (Non-parametric ANOVA) ====\n",
    "# Test if there's significant difference between store types\n",
    "groups = [group['total_sales'].values for name, group in store_metrics.groupby('type')]\n",
    "h_stat, p_value = stats.kruskal(*groups)\n",
    "\n",
    "print(\"=== Kruskal-Wallis Test: Sales ~ Store Type ===\")\n",
    "print(f\"H-statistic: {h_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.6f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"=> SIGNIFICANT difference between store types (p < 0.05)\")\n",
    "else:\n",
    "    print(\"=> NO significant difference between store types (p >= 0.05)\")\n",
    "\n",
    "# Pairwise comparisons (Mann-Whitney U)\n",
    "print(\"\\n=== Pairwise Mann-Whitney U Tests ===\")\n",
    "types = sorted(store_metrics['type'].unique())\n",
    "for i in range(len(types)):\n",
    "    for j in range(i+1, len(types)):\n",
    "        g1 = store_metrics[store_metrics['type'] == types[i]]['total_sales']\n",
    "        g2 = store_metrics[store_metrics['type'] == types[j]]['total_sales']\n",
    "        u_stat, p_val = stats.mannwhitneyu(g1, g2, alternative='two-sided')\n",
    "        sig = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"ns\"\n",
    "        print(f\"  {types[i]} vs {types[j]}: U={u_stat:.0f}, p={p_val:.4f} {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19d2515",
   "metadata": {},
   "source": [
    "## 5. Sales Distribution by Cluster (1-17)\n",
    "\n",
    "Clusters thường nhóm các stores có đặc tính tương tự. Phân tích xem clusters có ý nghĩa gì về mặt sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a22ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CLUSTER ANALYSIS ====\n",
    "cluster_metrics = store_metrics.groupby('cluster').agg(\n",
    "    num_stores=('store_nbr', 'count'),\n",
    "    avg_total_sales=('total_sales', 'mean'),\n",
    "    median_total_sales=('total_sales', 'median'),\n",
    "    avg_daily=('avg_daily_sales', 'mean'),\n",
    "    avg_cv=('cv', 'mean'),\n",
    "    avg_zero_pct=('zero_sales_pct', 'mean'),\n",
    "    types=('type', lambda x: ', '.join(sorted(x.unique())))\n",
    ").round(2)\n",
    "\n",
    "cluster_metrics = cluster_metrics.sort_values('avg_total_sales', ascending=False)\n",
    "print(\"Cluster metrics (sorted by avg total sales):\")\n",
    "print(cluster_metrics.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99316d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== BOX PLOTS: SALES BY CLUSTER ====\n",
    "fig, axes = plt.subplots(2, 1, figsize=(18, 12))\n",
    "\n",
    "# (A) Box plot: Total sales by cluster\n",
    "cluster_order = store_metrics.groupby('cluster')['total_sales'].median().sort_values(ascending=False).index\n",
    "sns.boxplot(data=store_metrics, x='cluster', y='total_sales', order=cluster_order, ax=axes[0], palette='coolwarm')\n",
    "axes[0].set_title('Total Sales Distribution by Cluster', fontweight='bold', fontsize=14)\n",
    "axes[0].set_ylabel('Total Sales ($)')\n",
    "axes[0].set_xlabel('Cluster')\n",
    "axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.0f}M'))\n",
    "\n",
    "# Add store counts\n",
    "for i, cl in enumerate(cluster_order):\n",
    "    n = (store_metrics['cluster'] == cl).sum()\n",
    "    axes[0].text(i, axes[0].get_ylim()[1] * 0.95, f'n={n}', ha='center', fontsize=8, color='gray')\n",
    "\n",
    "# (B) Bar plot: Average daily sales by cluster with type composition\n",
    "cluster_type_counts = store_metrics.groupby(['cluster', 'type']).size().unstack(fill_value=0)\n",
    "cluster_type_counts = cluster_type_counts.reindex(cluster_order)\n",
    "\n",
    "cluster_type_counts.plot(kind='bar', stacked=True, ax=axes[1], colormap='Set2', edgecolor='white')\n",
    "axes[1].set_title('Store Type Composition by Cluster', fontweight='bold', fontsize=14)\n",
    "axes[1].set_ylabel('Number of Stores')\n",
    "axes[1].set_xlabel('Cluster')\n",
    "axes[1].legend(title='Store Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/cluster_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996fecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CLUSTER HEATMAP: Cluster × Type CrossTab ====\n",
    "ct = pd.crosstab(store_metrics['cluster'], store_metrics['type'])\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(ct, annot=True, fmt='d', cmap='YlOrRd', cbar_kws={'label': 'Number of Stores'})\n",
    "plt.title('Cluster × Store Type Distribution', fontweight='bold', fontsize=14)\n",
    "plt.xlabel('Store Type')\n",
    "plt.ylabel('Cluster')\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/cluster_type_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Kruskal-Wallis Test: Sales ~ Cluster ===\")\n",
    "groups_cl = [group['total_sales'].values for name, group in store_metrics.groupby('cluster')]\n",
    "h_stat_cl, p_value_cl = stats.kruskal(*groups_cl)\n",
    "print(f\"H-statistic: {h_stat_cl:.4f}\")\n",
    "print(f\"P-value: {p_value_cl:.6f}\")\n",
    "if p_value_cl < 0.05:\n",
    "    print(\"=> SIGNIFICANT difference between clusters (p < 0.05)\")\n",
    "else:\n",
    "    print(\"=> NO significant difference between clusters (p >= 0.05)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44048a6c",
   "metadata": {},
   "source": [
    "## 6. Geographic Analysis: City & State\n",
    "\n",
    "Phân tích geographic patterns - Quito vs Guayaquil, coastal vs highland regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8b499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CITY ANALYSIS ====\n",
    "city_metrics = store_metrics.groupby('city').agg(\n",
    "    num_stores=('store_nbr', 'count'),\n",
    "    total_sales=('total_sales', 'sum'),\n",
    "    avg_total_sales=('total_sales', 'mean'),\n",
    "    avg_daily=('avg_daily_sales', 'mean'),\n",
    "    avg_cv=('cv', 'mean'),\n",
    "    states=('state', 'first')\n",
    ").reset_index()\n",
    "city_metrics = city_metrics.sort_values('avg_total_sales', ascending=False)\n",
    "\n",
    "print(\"City metrics:\")\n",
    "print(city_metrics.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50786565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== BAR CHART: AVERAGE SALES BY CITY ====\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 12))\n",
    "\n",
    "# (A) Average total sales per store by city\n",
    "city_sorted = city_metrics.sort_values('avg_total_sales', ascending=True)\n",
    "colors_city = plt.cm.viridis(np.linspace(0.2, 0.9, len(city_sorted)))\n",
    "bars = axes[0].barh(\n",
    "    [f\"{c} ({n})\" for c, n in zip(city_sorted['city'], city_sorted['num_stores'])],\n",
    "    city_sorted['avg_total_sales'] / 1e6,\n",
    "    color=colors_city\n",
    ")\n",
    "axes[0].set_xlabel('Average Total Sales per Store (Million $)')\n",
    "axes[0].set_title('Average Store Sales by City (# stores in parentheses)', fontweight='bold', fontsize=13)\n",
    "for bar, val in zip(bars, city_sorted['avg_total_sales'] / 1e6):\n",
    "    axes[0].text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2,\n",
    "                 f'${val:.1f}M', va='center', fontsize=8)\n",
    "\n",
    "# (B) Total sales contribution by city (stacked or grouped)\n",
    "city_total = city_metrics.sort_values('total_sales', ascending=True)\n",
    "bars2 = axes[1].barh(\n",
    "    city_total['city'],\n",
    "    city_total['total_sales'] / 1e6,\n",
    "    color=plt.cm.plasma(np.linspace(0.2, 0.9, len(city_total)))\n",
    ")\n",
    "axes[1].set_xlabel('Total Sales (Million $)')\n",
    "axes[1].set_title('Total Sales by City', fontweight='bold', fontsize=13)\n",
    "for bar, val, n in zip(bars2, city_total['total_sales'] / 1e6, city_total['num_stores']):\n",
    "    axes[1].text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2,\n",
    "                 f'${val:.0f}M ({n} stores)', va='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/city_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aa50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STATE ANALYSIS ====\n",
    "state_metrics = store_metrics.groupby('state').agg(\n",
    "    num_stores=('store_nbr', 'count'),\n",
    "    total_sales=('total_sales', 'sum'),\n",
    "    avg_total_sales=('total_sales', 'mean'),\n",
    "    avg_daily=('avg_daily_sales', 'mean'),\n",
    "    avg_cv=('cv', 'mean'),\n",
    "    cities=('city', lambda x: ', '.join(sorted(x.unique())))\n",
    ").reset_index()\n",
    "state_metrics = state_metrics.sort_values('avg_total_sales', ascending=False)\n",
    "\n",
    "print(\"State metrics:\")\n",
    "print(state_metrics.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f9c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== BAR CHART: AVERAGE SALES BY STATE ====\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# (A) Average sales per store by state\n",
    "state_sorted = state_metrics.sort_values('avg_total_sales', ascending=True)\n",
    "colors_s = plt.cm.RdYlGn(np.linspace(0.2, 0.9, len(state_sorted)))\n",
    "bars_s = axes[0].barh(\n",
    "    [f\"{s} ({n})\" for s, n in zip(state_sorted['state'], state_sorted['num_stores'])],\n",
    "    state_sorted['avg_total_sales'] / 1e6,\n",
    "    color=colors_s\n",
    ")\n",
    "axes[0].set_xlabel('Average Total Sales per Store (Million $)')\n",
    "axes[0].set_title('Average Store Sales by State', fontweight='bold', fontsize=13)\n",
    "\n",
    "# (B) Total sales by state\n",
    "state_total = state_metrics.sort_values('total_sales', ascending=True)\n",
    "axes[1].barh(\n",
    "    [f\"{s} ({n})\" for s, n in zip(state_total['state'], state_total['num_stores'])],\n",
    "    state_total['total_sales'] / 1e6,\n",
    "    color=plt.cm.coolwarm(np.linspace(0.2, 0.9, len(state_total)))\n",
    ")\n",
    "axes[1].set_xlabel('Total Sales (Million $)')\n",
    "axes[1].set_title('Total Sales by State', fontweight='bold', fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/state_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Quito vs Guayaquil comparison\n",
    "print(\"\\n=== Quito vs Guayaquil ===\")\n",
    "for city_name in ['Quito', 'Guayaquil']:\n",
    "    city_data = store_metrics[store_metrics['city'] == city_name]\n",
    "    print(f\"\\n{city_name}:\")\n",
    "    print(f\"  # Stores: {len(city_data)}\")\n",
    "    print(f\"  Total sales: ${city_data['total_sales'].sum():,.0f}\")\n",
    "    print(f\"  Avg sales per store: ${city_data['total_sales'].mean():,.0f}\")\n",
    "    print(f\"  Types: {dict(city_data['type'].value_counts())}\")\n",
    "    print(f\"  Clusters: {sorted(city_data['cluster'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be3d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== COASTAL vs HIGHLAND ANALYSIS ====\n",
    "# Ecuador geographic regions\n",
    "coastal_states = ['Guayas', 'Manabi', 'El Oro', 'Los Rios', 'Esmeraldas', 'Santa Elena']\n",
    "highland_states = ['Pichincha', 'Azuay', 'Tungurahua', 'Chimborazo', 'Cotopaxi',\n",
    "                   'Bolivar', 'Imbabura', 'Loja', 'Santo Domingo de los Tsachilas']\n",
    "\n",
    "store_metrics['region'] = store_metrics['state'].apply(\n",
    "    lambda x: 'Coastal' if x in coastal_states else ('Highland' if x in highland_states else 'Other')\n",
    ")\n",
    "\n",
    "region_metrics = store_metrics.groupby('region').agg(\n",
    "    num_stores=('store_nbr', 'count'),\n",
    "    total_sales=('total_sales', 'sum'),\n",
    "    avg_total_sales=('total_sales', 'mean'),\n",
    "    avg_daily=('avg_daily_sales', 'mean'),\n",
    "    avg_cv=('cv', 'mean')\n",
    ").round(2)\n",
    "\n",
    "print(\"=== Coastal vs Highland ===\")\n",
    "print(region_metrics)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# (A) Avg total sales by region\n",
    "region_sorted = region_metrics.sort_values('avg_total_sales', ascending=False)\n",
    "axes[0].bar(region_sorted.index, region_sorted['avg_total_sales'] / 1e6,\n",
    "            color=['#2196F3', '#4CAF50', '#FF9800'][:len(region_sorted)], edgecolor='white')\n",
    "axes[0].set_ylabel('Average Total Sales per Store (Million $)')\n",
    "axes[0].set_title('Average Store Sales: Coastal vs Highland', fontweight='bold')\n",
    "\n",
    "# (B) Box plot comparison\n",
    "sns.boxplot(data=store_metrics, x='region', y='total_sales', ax=axes[1], palette='Set2')\n",
    "axes[1].set_ylabel('Total Sales ($)')\n",
    "axes[1].set_title('Sales Distribution by Region', fontweight='bold')\n",
    "axes[1].yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.0f}M'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/coastal_vs_highland.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Statistical test\n",
    "coastal_sales = store_metrics[store_metrics['region'] == 'Coastal']['total_sales']\n",
    "highland_sales = store_metrics[store_metrics['region'] == 'Highland']['total_sales']\n",
    "if len(coastal_sales) > 0 and len(highland_sales) > 0:\n",
    "    u_stat, p_val = stats.mannwhitneyu(coastal_sales, highland_sales, alternative='two-sided')\n",
    "    print(f\"\\nMann-Whitney U Test (Coastal vs Highland): U={u_stat:.0f}, p={p_val:.4f}\")\n",
    "    print(f\"  => {'SIGNIFICANT' if p_val < 0.05 else 'NOT significant'} difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11252e5d",
   "metadata": {},
   "source": [
    "## 7. Store × Time Heatmap (Temporal Consistency)\n",
    "\n",
    "Đánh giá xem store performance có stable theo thời gian hay fluctuate nhiều."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f50e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STORE × MONTH HEATMAP ====\n",
    "# Aggregate sales by store and month\n",
    "df['year_month'] = df['date'].dt.to_period('M')\n",
    "store_monthly = df.groupby(['store_nbr', 'year_month'])['sales'].sum().reset_index()\n",
    "store_monthly['year_month_str'] = store_monthly['year_month'].astype(str)\n",
    "\n",
    "# Pivot for heatmap\n",
    "pivot_store_time = store_monthly.pivot_table(\n",
    "    index='store_nbr', columns='year_month', values='sales', aggfunc='sum'\n",
    ")\n",
    "\n",
    "# Sort stores by total sales\n",
    "store_order = store_metrics.sort_values('total_sales', ascending=False)['store_nbr'].values\n",
    "pivot_store_time = pivot_store_time.reindex(store_order)\n",
    "\n",
    "# Normalize each store by its own max (to see relative patterns)\n",
    "pivot_normalized = pivot_store_time.div(pivot_store_time.max(axis=1), axis=0)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(22, 16))\n",
    "\n",
    "# (A) Absolute heatmap\n",
    "sns.heatmap(pivot_store_time, cmap='YlOrRd', ax=axes[0],\n",
    "            xticklabels=6, yticklabels=True, cbar_kws={'label': 'Total Monthly Sales ($)'})\n",
    "axes[0].set_title('Store × Month Heatmap (Absolute Sales)', fontweight='bold', fontsize=14)\n",
    "axes[0].set_xlabel('Month')\n",
    "axes[0].set_ylabel('Store (sorted by total sales)')\n",
    "axes[0].tick_params(axis='y', labelsize=7)\n",
    "\n",
    "# (B) Normalized heatmap (each store relative to its own max)\n",
    "sns.heatmap(pivot_normalized, cmap='YlGnBu', ax=axes[1],\n",
    "            xticklabels=6, yticklabels=True, cbar_kws={'label': 'Relative Sales (0-1)'})\n",
    "axes[1].set_title('Store × Month Heatmap (Normalized per Store)', fontweight='bold', fontsize=14)\n",
    "axes[1].set_xlabel('Month')\n",
    "axes[1].set_ylabel('Store (sorted by total sales)')\n",
    "axes[1].tick_params(axis='y', labelsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/store_time_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STORE PERFORMANCE CONSISTENCY OVER YEARS ====\n",
    "df['year'] = df['date'].dt.year\n",
    "store_yearly = df.groupby(['store_nbr', 'year'])['sales'].sum().reset_index()\n",
    "pivot_yearly = store_yearly.pivot_table(index='store_nbr', columns='year', values='sales')\n",
    "\n",
    "# Calculate year-over-year rank stability\n",
    "yearly_ranks = pivot_yearly.rank(ascending=False)\n",
    "rank_std = yearly_ranks.std(axis=1).sort_values()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# (A) Line chart: Top 10 stores yearly trajectory\n",
    "top10_stores = store_metrics.head(10)['store_nbr'].values\n",
    "for s in top10_stores:\n",
    "    if s in pivot_yearly.index:\n",
    "        axes[0].plot(pivot_yearly.columns, pivot_yearly.loc[s] / 1e6, marker='o', label=f'Store {int(s)}')\n",
    "axes[0].set_xlabel('Year')\n",
    "axes[0].set_ylabel('Total Sales (Million $)')\n",
    "axes[0].set_title('Yearly Sales Trajectory: Top 10 Stores', fontweight='bold')\n",
    "axes[0].legend(fontsize=8, ncol=2)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# (B) Rank stability\n",
    "most_stable = rank_std.head(10)\n",
    "least_stable = rank_std.tail(10)\n",
    "stability = pd.concat([most_stable, least_stable])\n",
    "colors_stab = ['green'] * 10 + ['red'] * 10\n",
    "axes[1].barh(\n",
    "    [f\"Store {int(s)}\" for s in stability.index],\n",
    "    stability.values,\n",
    "    color=colors_stab\n",
    ")\n",
    "axes[1].set_xlabel('Rank Std Dev (lower = more stable)')\n",
    "axes[1].set_title('Most Stable (green) vs Least Stable (red) Stores', fontweight='bold')\n",
    "axes[1].axvline(x=rank_std.median(), color='gray', linestyle='--', alpha=0.5, label=f'Median={rank_std.median():.1f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/store_consistency.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== Most Stable Stores (consistent rank over years) ===\")\n",
    "for s in most_stable.index[:5]:\n",
    "    m = store_metrics[store_metrics['store_nbr'] == s].iloc[0]\n",
    "    print(f\"  Store {int(s)}: {m['city']}, Type {m['type']}, Cluster {int(m['cluster'])}, Rank StdDev={most_stable[s]:.2f}\")\n",
    "\n",
    "print(\"\\n=== Least Stable Stores (fluctuating rank) ===\")\n",
    "for s in least_stable.index[-5:]:\n",
    "    m = store_metrics[store_metrics['store_nbr'] == s].iloc[0]\n",
    "    print(f\"  Store {int(s)}: {m['city']}, Type {m['type']}, Cluster {int(m['cluster'])}, Rank StdDev={least_stable[s]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0122bd6",
   "metadata": {},
   "source": [
    "## 8. Store Characteristics vs Sales (Scatter Plots)\n",
    "\n",
    "Tìm patterns giữa các đặc tính của store và sales performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== SCATTER PLOTS: STORE CHARACTERISTICS vs SALES ====\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# (A) Zero sales % vs Total sales\n",
    "axes[0, 0].scatter(store_metrics['zero_sales_pct'], store_metrics['total_sales'] / 1e6,\n",
    "                   c=store_metrics['type'].map({'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}),\n",
    "                   cmap='Set1', s=80, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Zero Sales %')\n",
    "axes[0, 0].set_ylabel('Total Sales (Million $)')\n",
    "axes[0, 0].set_title('Zero Sales % vs Total Sales', fontweight='bold')\n",
    "# Add correlation\n",
    "r, p = stats.pearsonr(store_metrics['zero_sales_pct'], store_metrics['total_sales'])\n",
    "axes[0, 0].text(0.05, 0.95, f'r={r:.3f}, p={p:.4f}', transform=axes[0, 0].transAxes,\n",
    "                fontsize=10, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat'))\n",
    "\n",
    "# (B) CV vs Total sales\n",
    "axes[0, 1].scatter(store_metrics['cv'], store_metrics['total_sales'] / 1e6,\n",
    "                   c=store_metrics['cluster'], cmap='tab20', s=80, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_xlabel('Coefficient of Variation')\n",
    "axes[0, 1].set_ylabel('Total Sales (Million $)')\n",
    "axes[0, 1].set_title('Sales Volatility vs Total Sales (color=cluster)', fontweight='bold')\n",
    "\n",
    "# (C) Cluster vs Average daily sales (jitter plot)\n",
    "for t in sorted(store_metrics['type'].unique()):\n",
    "    mask = store_metrics['type'] == t\n",
    "    axes[1, 0].scatter(store_metrics[mask]['cluster'] + np.random.uniform(-0.2, 0.2, mask.sum()),\n",
    "                       store_metrics[mask]['avg_daily_sales'],\n",
    "                       label=f'Type {t}', s=60, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Cluster')\n",
    "axes[1, 0].set_ylabel('Average Daily Sales ($)')\n",
    "axes[1, 0].set_title('Cluster × Type → Daily Sales', fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=8)\n",
    "\n",
    "# (D) Number of stores in city vs avg sales\n",
    "city_plot = city_metrics.copy()\n",
    "axes[1, 1].scatter(city_plot['num_stores'], city_plot['avg_total_sales'] / 1e6,\n",
    "                   s=city_plot['total_sales'] / city_plot['total_sales'].max() * 500,\n",
    "                   alpha=0.6, edgecolor='black', c='steelblue')\n",
    "for _, row in city_plot.iterrows():\n",
    "    axes[1, 1].annotate(row['city'], (row['num_stores'], row['avg_total_sales'] / 1e6),\n",
    "                        fontsize=7, ha='center', va='bottom')\n",
    "axes[1, 1].set_xlabel('Number of Stores in City')\n",
    "axes[1, 1].set_ylabel('Avg Total Sales per Store (Million $)')\n",
    "axes[1, 1].set_title('City Store Density vs Avg Sales (size=total sales)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/scatter_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec08d621",
   "metadata": {},
   "source": [
    "## 9. Outlier & Zero-Sales Deep Dive\n",
    "\n",
    "Nhận diện stores có unusual patterns - quá nhiều zero sales hoặc sales volatility bất thường."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61166eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== OUTLIER DETECTION ====\n",
    "# Z-score based outlier detection on store-level metrics\n",
    "from scipy.stats import zscore\n",
    "\n",
    "metrics_for_outlier = ['total_sales', 'avg_daily_sales', 'cv', 'zero_sales_pct']\n",
    "z_scores = store_metrics[metrics_for_outlier].apply(zscore)\n",
    "z_scores.index = store_metrics['store_nbr']\n",
    "\n",
    "# Flag stores with |z| > 2 on any metric\n",
    "outlier_mask = (z_scores.abs() > 2).any(axis=1)\n",
    "outlier_stores = store_metrics[store_metrics['store_nbr'].isin(z_scores[outlier_mask].index)]\n",
    "\n",
    "print(f\"Outlier stores detected: {len(outlier_stores)}\")\n",
    "if len(outlier_stores) > 0:\n",
    "    print(\"\\nOutlier details:\")\n",
    "    print(outlier_stores[['store_nbr', 'city', 'state', 'type', 'cluster',\n",
    "                          'total_sales', 'avg_daily_sales', 'cv', 'zero_sales_pct']].to_string(index=False))\n",
    "\n",
    "# Z-score heatmap for all stores\n",
    "fig, ax = plt.subplots(figsize=(12, 16))\n",
    "z_display = z_scores.reindex(store_metrics.sort_values('total_sales', ascending=False)['store_nbr'])\n",
    "sns.heatmap(z_display, annot=True, fmt='.1f', cmap='RdYlGn_r', center=0, ax=ax,\n",
    "            yticklabels=[f\"Store {int(s)}\" for s in z_display.index],\n",
    "            cbar_kws={'label': 'Z-Score'})\n",
    "ax.set_title('Store Metrics Z-Scores (Red = Unusual)', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/outlier_zscore.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== ZERO SALES DEEP DIVE ====\n",
    "# Which stores have unusually high zero-sales rates?\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# (A) Zero sales % by store (sorted)\n",
    "zero_sorted = store_metrics.sort_values('zero_sales_pct', ascending=False)\n",
    "colors_zero = ['red' if z > 40 else 'orange' if z > 30 else 'green'\n",
    "               for z in zero_sorted['zero_sales_pct']]\n",
    "axes[0].barh(\n",
    "    [f\"Store {int(s)}\" for s in zero_sorted['store_nbr']],\n",
    "    zero_sorted['zero_sales_pct'],\n",
    "    color=colors_zero\n",
    ")\n",
    "axes[0].set_xlabel('Zero Sales %')\n",
    "axes[0].set_title('Zero Sales Rate by Store', fontweight='bold')\n",
    "axes[0].axvline(x=store_metrics['zero_sales_pct'].mean(), color='black', linestyle='--',\n",
    "                label=f\"Mean={store_metrics['zero_sales_pct'].mean():.1f}%\")\n",
    "axes[0].legend()\n",
    "axes[0].tick_params(axis='y', labelsize=6)\n",
    "\n",
    "# (B) Zero sales % by store type\n",
    "sns.boxplot(data=store_metrics, x='type', y='zero_sales_pct', ax=axes[1], palette='RdYlGn_r')\n",
    "axes[1].set_title('Zero Sales Rate by Store Type', fontweight='bold')\n",
    "axes[1].set_ylabel('Zero Sales %')\n",
    "axes[1].set_xlabel('Store Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/zero_sales_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print stores with highest zero-sales rates\n",
    "print(\"=== Stores with Highest Zero-Sales Rates ===\")\n",
    "high_zero = store_metrics.nlargest(5, 'zero_sales_pct')\n",
    "for _, row in high_zero.iterrows():\n",
    "    print(f\"  Store {int(row['store_nbr'])}: {row['zero_sales_pct']:.1f}% zero sales \"\n",
    "          f\"({row['city']}, Type {row['type']}, Cluster {int(row['cluster'])})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c2be9",
   "metadata": {},
   "source": [
    "## 10. Product Family Performance by Store Type\n",
    "\n",
    "Phân tích xem các store types khác nhau có bán các product families khác nhau không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fac8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== PRODUCT FAMILY × STORE TYPE ====\n",
    "family_type = df.groupby(['type', 'family'])['sales'].sum().reset_index()\n",
    "top_families = df.groupby('family')['sales'].sum().nlargest(10).index\n",
    "\n",
    "# Filter top families for clarity\n",
    "family_type_top = family_type[family_type['family'].isin(top_families)]\n",
    "pivot_ft = family_type_top.pivot_table(index='family', columns='type', values='sales', aggfunc='sum')\n",
    "\n",
    "# Normalize by type total to see % composition\n",
    "pivot_ft_pct = pivot_ft.div(pivot_ft.sum(axis=0), axis=1) * 100\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# (A) Absolute sales heatmap\n",
    "sns.heatmap(pivot_ft / 1e6, annot=True, fmt='.1f', cmap='YlOrRd', ax=axes[0],\n",
    "            cbar_kws={'label': 'Sales (Million $)'})\n",
    "axes[0].set_title('Top 10 Families × Store Type (Absolute Sales)', fontweight='bold')\n",
    "axes[0].set_ylabel('Product Family')\n",
    "axes[0].set_xlabel('Store Type')\n",
    "\n",
    "# (B) Percentage composition heatmap\n",
    "sns.heatmap(pivot_ft_pct, annot=True, fmt='.1f', cmap='Blues', ax=axes[1],\n",
    "            cbar_kws={'label': '% of Type Total'})\n",
    "axes[1].set_title('Top 10 Families × Store Type (% Composition)', fontweight='bold')\n",
    "axes[1].set_ylabel('Product Family')\n",
    "axes[1].set_xlabel('Store Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/family_by_type.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3627e88",
   "metadata": {},
   "source": [
    "## 11. Store Predictability Score\n",
    "\n",
    "Đánh giá stores nào dễ predict hơn dựa trên variance, zero-sales, và consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954bfe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== PREDICTABILITY SCORE ====\n",
    "# Higher score = easier to predict\n",
    "# Components: inverse CV, low zero-sales%, rank stability\n",
    "store_metrics['cv_score'] = 1 - (store_metrics['cv'] - store_metrics['cv'].min()) / (store_metrics['cv'].max() - store_metrics['cv'].min())\n",
    "store_metrics['zero_score'] = 1 - (store_metrics['zero_sales_pct'] - store_metrics['zero_sales_pct'].min()) / (store_metrics['zero_sales_pct'].max() - store_metrics['zero_sales_pct'].min())\n",
    "\n",
    "# Add rank stability (from yearly analysis)\n",
    "rank_std_series = yearly_ranks.std(axis=1)\n",
    "store_metrics = store_metrics.merge(\n",
    "    rank_std_series.reset_index().rename(columns={'index': 'store_nbr', 0: 'rank_std'}),\n",
    "    on='store_nbr', how='left'\n",
    ")\n",
    "store_metrics['stability_score'] = 1 - (store_metrics['rank_std'] - store_metrics['rank_std'].min()) / (store_metrics['rank_std'].max() - store_metrics['rank_std'].min())\n",
    "\n",
    "# Composite score\n",
    "store_metrics['predictability'] = (\n",
    "    0.4 * store_metrics['cv_score'] +\n",
    "    0.3 * store_metrics['zero_score'] +\n",
    "    0.3 * store_metrics['stability_score']\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# (A) Predictability score distribution\n",
    "pred_sorted = store_metrics.sort_values('predictability', ascending=True)\n",
    "colors_pred = plt.cm.RdYlGn(pred_sorted['predictability'])\n",
    "axes[0].barh(\n",
    "    [f\"Store {int(s)} ({t})\" for s, t in zip(pred_sorted['store_nbr'], pred_sorted['type'])],\n",
    "    pred_sorted['predictability'],\n",
    "    color=colors_pred\n",
    ")\n",
    "axes[0].set_xlabel('Predictability Score (higher = easier to forecast)')\n",
    "axes[0].set_title('Store Predictability Score', fontweight='bold')\n",
    "axes[0].tick_params(axis='y', labelsize=6)\n",
    "\n",
    "# (B) Predictability by type\n",
    "sns.boxplot(data=store_metrics, x='type', y='predictability', ax=axes[1], palette='RdYlGn')\n",
    "axes[1].set_title('Predictability Score by Store Type', fontweight='bold')\n",
    "axes[1].set_ylabel('Predictability Score')\n",
    "axes[1].set_xlabel('Store Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/predictability_score.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(\"=== Most Predictable Stores ===\")\n",
    "for _, row in store_metrics.nlargest(5, 'predictability').iterrows():\n",
    "    print(f\"  Store {int(row['store_nbr'])}: Score={row['predictability']:.3f} \"\n",
    "          f\"({row['city']}, Type {row['type']}, CV={row['cv']:.2f})\")\n",
    "\n",
    "print(\"\\n=== Least Predictable Stores ===\")\n",
    "for _, row in store_metrics.nsmallest(5, 'predictability').iterrows():\n",
    "    print(f\"  Store {int(row['store_nbr'])}: Score={row['predictability']:.3f} \"\n",
    "          f\"({row['city']}, Type {row['type']}, CV={row['cv']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35642c7b",
   "metadata": {},
   "source": [
    "## 12. Modeling Recommendations\n",
    "\n",
    "Dựa trên kết quả phân tích, đưa ra recommendations cho strategy modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a1d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== MODELING STRATEGY ANALYSIS ====\n",
    "print(\"=\"*70)\n",
    "print(\"MODELING RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Should we model by store type?\n",
    "print(\"\\n1. MODEL BY STORE TYPE?\")\n",
    "type_cv_mean = store_metrics.groupby('type')['cv'].mean()\n",
    "type_sales_mean = store_metrics.groupby('type')['avg_daily_sales'].mean()\n",
    "print(f\"   Type-level CV (lower = more predictable):\")\n",
    "for t in sorted(type_cv_mean.index):\n",
    "    print(f\"     Type {t}: CV={type_cv_mean[t]:.3f}, Avg Daily=${type_sales_mean[t]:,.0f}\")\n",
    "\n",
    "# 2. Should we model by cluster?\n",
    "print(\"\\n2. MODEL BY CLUSTER?\")\n",
    "within_cluster_cv = store_metrics.groupby('cluster')['total_sales'].apply(\n",
    "    lambda x: x.std() / x.mean() if x.mean() > 0 else np.inf\n",
    ")\n",
    "print(f\"   Within-cluster CV (lower = more homogeneous):\")\n",
    "print(f\"   Mean: {within_cluster_cv.mean():.3f}\")\n",
    "print(f\"   Range: {within_cluster_cv.min():.3f} - {within_cluster_cv.max():.3f}\")\n",
    "print(f\"   => Clusters {'ARE' if within_cluster_cv.mean() < 0.5 else 'MAY NOT BE'} good grouping variables\")\n",
    "\n",
    "# 3. Region-based modeling\n",
    "print(\"\\n3. MODEL BY REGION?\")\n",
    "region_cv = store_metrics.groupby('region')['total_sales'].apply(\n",
    "    lambda x: x.std() / x.mean() if x.mean() > 0 else np.inf\n",
    ")\n",
    "for r in region_cv.index:\n",
    "    n = (store_metrics['region'] == r).sum()\n",
    "    print(f\"   {r}: within-group CV={region_cv[r]:.3f} (n={n})\")\n",
    "\n",
    "# 4. Individual store models\n",
    "print(\"\\n4. INDIVIDUAL STORE MODELS?\")\n",
    "high_sales_stores = store_metrics[store_metrics['total_sales'] > store_metrics['total_sales'].quantile(0.75)]\n",
    "print(f\"   High-volume stores (top 25%): {len(high_sales_stores)} stores\")\n",
    "print(f\"   These may benefit from individual models due to unique patterns\")\n",
    "print(f\"   Stores: {sorted(high_sales_stores['store_nbr'].values)}\")\n",
    "\n",
    "# 5. Summary table\n",
    "print(\"\\n5. STRATEGY SUMMARY:\")\n",
    "print(\"   ┌────────────────────────────┬─────────────────────────────────┐\")\n",
    "print(\"   │ Approach                   │ Recommendation                  │\")\n",
    "print(\"   ├────────────────────────────┼─────────────────────────────────┤\")\n",
    "print(\"   │ Global model (all stores)  │ Baseline, but loses nuance      │\")\n",
    "print(\"   │ Model per store type       │ Good if type differences signif │\")\n",
    "print(\"   │ Model per cluster          │ Depends on cluster homogeneity  │\")\n",
    "print(\"   │ Model per store            │ Best for top stores, expensive  │\")\n",
    "print(\"   │ Hierarchical model         │ Best balance of accuracy/cost   │\")\n",
    "print(\"   └────────────────────────────┴─────────────────────────────────┘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66321f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== EXPORT STORE METRICS ====\n",
    "export_cols = ['store_nbr', 'city', 'state', 'type', 'cluster', 'region',\n",
    "               'total_sales', 'avg_daily_sales', 'median_daily_sales', 'std_daily_sales',\n",
    "               'cv', 'zero_sales_pct', 'rank_total', 'predictability']\n",
    "store_metrics[export_cols].sort_values('store_nbr').to_csv('outputs/store_metrics.csv', index=False)\n",
    "print(\"Store metrics exported to outputs/store_metrics.csv\")\n",
    "print(f\"Shape: {store_metrics[export_cols].shape}\")\n",
    "store_metrics[export_cols].sort_values('rank_total').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d65ca",
   "metadata": {},
   "source": [
    "## 13. Summary & Key Findings\n",
    "\n",
    "### Store Segmentation Insights\n",
    "- **Store Type** là yếu tố phân biệt quan trọng: Type A/D thường có sales cao hơn Type C/E\n",
    "- **Cluster** giúp nhóm stores có behavior tương tự, hữu ích cho hierarchical modeling\n",
    "- **Predictability** khác nhau đáng kể giữa stores → cần cân nhắc chiến lược model riêng\n",
    "\n",
    "### Geographic Insights\n",
    "- **Quito** (Pichincha) chiếm phần lớn stores và sales → market chính\n",
    "- **Guayaquil** (Guayas) là market lớn thứ hai, coastal region\n",
    "- Sự khác biệt Coastal vs Highland ảnh hưởng đến consumer behavior\n",
    "\n",
    "### Data Quality Notes\n",
    "- ~31% records có zero sales → cần xử lý cẩn thận\n",
    "- Một số stores có zero-sales rate rất cao → có thể là stores mới hoặc stores nhỏ\n",
    "- Sales distribution highly right-skewed → nên dùng log transform hoặc robust methods\n",
    "\n",
    "### Recommendations cho Modeling\n",
    "1. **Hierarchical approach**: Model theo store type/cluster sẽ tốt hơn global model\n",
    "2. **Top stores**: Nên có individual models cho top 10-15 stores (chiếm ~40% sales)\n",
    "3. **Feature engineering**: Store type, cluster, city, region nên là features quan trọng\n",
    "4. **Zero sales handling**: Cần strategy riêng cho stores có high zero-sales rate\n",
    "5. **Temporal features**: Store performance patterns thay đổi theo mùa → seasonal features critical"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
